{
  
    
        "post0": {
            "title": "A- Sentence Level Analysis",
            "content": "import pandas as pd import numpy as np import re from textblob import TextBlob from wordcloud import WordCloud import matplotlib.pyplot as plt import seaborn as sns import string import nltk import warnings %matplotlib inline ## Install this on a new system # nltk.download(&#39;punkt&#39;) from nltk.tokenize import word_tokenize warnings.filterwarnings(&#39;ignore&#39;) plt.style.use(&#39;fivethirtyeight&#39;) . Get the overall info from the dataset . toronto_df = pd.read_csv(&quot;textdata/Toronto-dataset.csv&quot;) . toronto_df.head(5) . coordinates created_at hashtags media urls favorite_count id in_reply_to_screen_name in_reply_to_status_id in_reply_to_user_id ... user_followers_count user_friends_count user_listed_count user_location user_name user_screen_name.1 user_statuses_count user_time_zone user_urls user_verified . 0 -79.3872,43.648 | Thu Mar 26 22:45:10 +0000 2020 | NaN | NaN | https://www.instagram.com/p/B-Ns5S9hrgl/?igshi... | 1 | 1243308037366046721 | NaN | NaN | NaN | ... | 330 | 168 | 21 | Canada | Simply Eseeri | SimplyEseeri | 9533 | NaN | http://simplyeseeri.com | False | . 1 -79.4523813,43.7143142 | Fri Mar 20 13:22:05 +0000 2020 | NaN | NaN | NaN | 0 | 1240992007184691200 | NaN | NaN | NaN | ... | 11322 | 9 | 319 | NaN | Toronto Fire | tofire | 1572636 | NaN | https://iaingrant.com | False | . 2 -79.38512824,43.6408863 | Thu Mar 26 02:04:15 +0000 2020 | BTPENT dttheartist Toronto artistlife isignmys... | NaN | https://www.instagram.com/p/B-Le4FXFBPS/?igshi... | 0 | 1242995752416079872 | NaN | NaN | NaN | ... | 1060 | 1054 | 23 | Toronto | DT The Artist | dttheartist | 11574 | NaN | http://www.dttheartist.com | False | . 3 -79.38512824,43.6408863 | Wed Mar 25 20:11:32 +0000 2020 | corona | NaN | https://www.instagram.com/p/B-K2VgrlEVy/?igshi... | 0 | 1242906988675321861 | NaN | NaN | NaN | ... | 2691 | 5217 | 5 | Toronto, Ontario | muzic souljah 1 | muzicsouljah1 | 1532 | NaN | http://paradigmgroupentertainment.ca | False | . 4 -79.3872,43.648 | Wed Mar 25 03:29:35 +0000 2020 | stayhome covid_19 corona coronamemes quotes se... | NaN | https://www.instagram.com/p/B-JD2mGAth0/?igshi... | 0 | 1242654837713625089 | NaN | NaN | NaN | ... | 266 | 382 | 8 | Toronto, Ontario | Argentina Beltran gabe+angel | gabeandangel | 1032 | NaN | https://linktr.ee/gabeandangel | False | . 5 rows √ó 34 columns . # toronto_df.info() # toronto_df.head(5) ## Create a dataframe with a column for tweets #df_text = toronto_df[&#39;text&#39;] # df_text = toronto_df[[&#39;text&#39;]].convert_dtypes(object,str) df_text = toronto_df[[&#39;text&#39;]].convert_dtypes(object,str) df_text[&#39;created_at&#39;] = toronto_df[[&#39;created_at&#39;]].convert_dtypes(object,str) df_text[&#39;place&#39;] = toronto_df[[&#39;place&#39;]].convert_dtypes(object,str) df_text[&#39;hashtags&#39;] = toronto_df[[&#39;hashtags&#39;]].convert_dtypes(object,str) # df_timebased_tweets = ## Perhaps we need the hashtags too # created_at , hashtags, place #df_text = toronto_df[[&#39;hashtags&#39;,&#39;text&#39;]] #df_text.info() # df_text.head(10) . df_text.head(10) . text created_at place hashtags . 0 What have I‚Äôve been up to? ‚Å£‚Å£ ‚Å£Washing my hand... | Thu Mar 26 22:45:10 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | . 1 Alarm (highrise Residential) [North York] Lawr... | Fri Mar 20 13:22:05 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | . 2 How @mr4_dh and myself pass people when we see... | Thu Mar 26 02:04:15 +0000 2020 | Toronto, Ontario | BTPENT dttheartist Toronto artistlife isignmys... | . 3 Life b4 #coronaüç∫ @ Toronto C‚Ä¢A‚Ä¢N‚Ä¢A‚Ä¢D‚Ä¢A https:/... | Wed Mar 25 20:11:32 +0000 2020 | Toronto, Ontario | corona | . 4 Let‚Äôs all be brave and stay at home yeah? #sta... | Wed Mar 25 03:29:35 +0000 2020 | Toronto, Ontario | stayhome covid_19 corona coronamemes quotes se... | . 5 Sending love wherever it‚Äôs needed üíï‚òÆÔ∏è#uponocca... | Mon Mar 23 13:22:42 +0000 2020 | Toronto, Ontario | uponoccasion uponoccasionevents sendinglove lo... | . 6 Thursday night, corona time, isolated 18 floor... | Fri Mar 20 01:00:28 +0000 2020 | Toronto, Ontario | netflix amazonprime tequila donjulio70 hope li... | . 7 Shibani Kashyap‚Äôs new tune: ‚ÄòCorona ko hai har... | Sat Mar 28 16:27:32 +0000 2020 | Brampton, Ontario | Entertainment EntertainmentMusic | . 8 People in Toronto are ‚ÄúAnnoyed‚Äù by this opera ... | Tue Mar 24 18:22:20 +0000 2020 | Toronto, Ontario | covid_19 socialdistancing coronavirus corona f... | . 9 Hey hey hey m&#39;fitties! B.C. = BEFORE CORONA. ... | Mon Mar 30 16:22:29 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | . Cleaning the text Data . def cleanEmoji(text): regrex_pattern = re.compile(pattern = &quot;[&quot; u&quot; U0001F600- U0001F64F&quot; # emoticons u&quot; U0001F300- U0001F5FF&quot; # symbols &amp; pictographs u&quot; U0001F680- U0001F6FF&quot; # transport &amp; map symbols u&quot; U0001F1E0- U0001F1FF&quot; # flags (iOS) u&quot; U00002702- U000027B0&quot; u&quot; U000024C2- U0001F251&quot; &quot;]+&quot;, flags = re.UNICODE) return regrex_pattern.sub(r&#39;&#39;,text) #2-CleanTweets function replaces non-text entities with space def cleanTweets(text): text = re.sub(r&#39;@[A-Za-z0-9]&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove @mentions text = re.sub(r&#39;#&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Removing the # symbol text = re.sub(r&#39;@&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Removing the # symbol text = re.sub(r&#39;RT[ s]+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove RT text = re.sub(r&#39;https?: / / S+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove the hyper link text = re.sub(r&#39;http?: / / S+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove the hyper link text = re.sub(r&#39;^https?: / /.*[ r n]*&#39;, &#39;&#39;, text, flags=re.MULTILINE) # Note: remove special charactres and punctuations - text = re.sub(r&#39;[^a-zA-Z# ]&#39;,&#39;&#39;,text, flags=re.MULTILINE) #text = re.sub(&#39;https&#39;, &#39;&#39;, text, flags=re.MULTILINE) #text = re.sub(&#39;https&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;urbanstreetphotography&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;igstreet&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;cityscape&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;streetphotographer&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;urbanstreetphotogallery&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;photodocumentary&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;ig_street&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Covid&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;COVID&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;covid&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;spicollective&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Spicollective&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;lensculture&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Toronto&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Ontario&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;will&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;bnw&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;bw&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(r&#39; xc2 xb7&#39;,&#39;&#39;,text) # Remove bullet points text = re.sub(r&#39; u2022&#39;,&#39;&#39;,text) # Remove bullet points # text = re.sub(r&#39;https?: / /(www .)?[-a-zA-Z0‚Äì9@:%._ +~#=]{2,256} .[a-z]{2,6} b([-a-zA-Z0‚Äì9@:%_ +.~#?&amp;//=]*)&#39;, # &#39;&#39;, text, flags=re.MULTILINE) # Remove links that start with HTTP/HTTPS in the tweet # text = re.sub(r&#39;[-a-zA-Z0‚Äì9@:%._ +~#=]{2,256} .[a-z]{2,6} b([-a-zA-Z0‚Äì9@:%_ +.~#?&amp;//=]*)&#39;, # &#39;&#39;, text, flags=re.MULTILINE) # Remove other url links return text . # s = df_text.iloc[[2]] df_text[&#39;text&#39;] = df_text[&#39;text&#39;].apply(cleanTweets) df_text[&#39;text&#39;] = df_text[&#39;text&#39;].apply(cleanEmoji) . df_text.head(2) . text created_at place hashtags . 0 What have Ive been up to Washing my hands soci... | Thu Mar 26 22:45:10 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | . 1 Alarm highrise Residential North YorkLawrence ... | Fri Mar 20 13:22:05 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | . Start working on the contect and subject area . def getSubjectivity(text): return TextBlob(text).sentiment.subjectivity #create a function to get the polarity def getPolarity(text): return TextBlob(text).sentiment.polarity #Create two new columns to add the sentiment and polarity df_text[&#39;subjectivity&#39;] = df_text[&#39;text&#39;].apply(getSubjectivity) df_text[&#39;polarity&#39;] = df_text[&#39;text&#39;].apply(getPolarity) #Display the new dataset df_text.head(10) . text created_at place hashtags subjectivity polarity . 0 What have Ive been up to Washing my hands soci... | Thu Mar 26 22:45:10 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | 0.533333 | 0.016667 | . 1 Alarm highrise Residential North YorkLawrence ... | Fri Mar 20 13:22:05 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | 0.000000 | 0.000000 | . 2 How rdh and myself pass people when we see the... | Thu Mar 26 02:04:15 +0000 2020 | Toronto, Ontario | BTPENT dttheartist Toronto artistlife isignmys... | 0.000000 | 0.000000 | . 3 Life b corona CANADA | Wed Mar 25 20:11:32 +0000 2020 | Toronto, Ontario | corona | 0.000000 | 0.000000 | . 4 Lets all be brave and stay at home yeah stayho... | Wed Mar 25 03:29:35 +0000 2020 | Toronto, Ontario | stayhome covid_19 corona coronamemes quotes se... | 1.000000 | 0.800000 | . 5 Sending love wherever its needed uponoccasion ... | Mon Mar 23 13:22:42 +0000 2020 | Toronto, Ontario | uponoccasion uponoccasionevents sendinglove lo... | 0.600000 | 0.500000 | . 6 Thursday night corona time isolated floors up... | Fri Mar 20 01:00:28 +0000 2020 | Toronto, Ontario | netflix amazonprime tequila donjulio70 hope li... | 1.000000 | -0.500000 | . 7 Shibani Kashyaps new tune Corona ko hai harana... | Sat Mar 28 16:27:32 +0000 2020 | Brampton, Ontario | Entertainment EntertainmentMusic | 0.677273 | 0.368182 | . 8 People in are Annoyed by this opera singer gi... | Tue Mar 24 18:22:20 +0000 2020 | Toronto, Ontario | covid_19 socialdistancing coronavirus corona f... | 0.800000 | -0.400000 | . 9 Hey hey hey mfittiesBC BEFORE CORONA D So wan... | Mon Mar 30 16:22:29 +0000 2020 | Toronto, Ontario | &lt;NA&gt; | 0.700000 | -0.400000 | . Make a WordCloud chart -word frequency map . # visualize the most frequency used words allWords = &#39; &#39;.join(twts for twts in df_text[&#39;text&#39;]) wordCloud = WordCloud(width=800, height=500, random_state=21,max_font_size=119).generate(allWords) plt.figure(figsize=(19,8)) plt.imshow(wordCloud, interpolation= &#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.show() . Positive and Negative Sentiments . def getSentAnalysis(score): if score &lt; 0: return &quot;Negative&quot; elif score == 0: return &#39;Neutral&#39; else: return &#39;Positive&#39; # Add column analysis and add a label such as positive-negative-neutral to each tweet df_text[&#39;analysis&#39;] = df_text[&#39;polarity&#39;].apply(getSentAnalysis) #df_text . All Negative Tweets . j=1 sortedDF_text = df_text.sort_values(by=[&#39;polarity&#39;]) for i in range(0, sortedDF_text.shape[0]): if (sortedDF_text[&#39;analysis&#39;][i] == &#39;Negative&#39;): # print(str(j)+ &#39;)&#39; + sortedDF_text[&#39;text&#39;][i]) # print() j = j+1 . All Positive Tweets . j=1 sortedDF_text = df_text.sort_values(by=[&#39;polarity&#39;]) for i in range(0, sortedDF_text.shape[0]): if (sortedDF_text[&#39;analysis&#39;][i] == &#39;Positive&#39;): # print(str(j)+ &#39;)&#39; + sortedDF_text[&#39;text&#39;][i]) # print() j = j+1 . Scatter pLot - map the postitive-negative distribution . plt.figure(figsize=(12,8)) for i in range(0,df_text.shape[0]): plt.scatter(df_text[&#39;polarity&#39;][i],df_text[&#39;subjectivity&#39;][i], color=&#39;Blue&#39;) plt.title(&#39;Sentiment Analysis&#39;) plt.xlabel(&#39;Subjectivity&#39;) plt.xlabel(&#39;Polarity&#39;) plt.show() . Overall picture: Positive, Negative, Neutral . ## Percentage of Positive Tweets ptweets = df_text[df_text.analysis == &#39;Positive&#39;] ptweets = ptweets [&#39;text&#39;] positivetweets = round ((ptweets.shape[0] /df_text.shape[0]) *100,1) print (f&quot;--&gt; percentage of positive tweets: {positivetweets} %&quot;) . --&gt; percentage of positive tweets: 50.3 % . ntweets = df_text[df_text.analysis == &#39;Negative&#39;] ntweets = ntweets[&#39;text&#39;] ## Percentage of Negative Tweets negativetweets = round( (ntweets.shape[0] / df_text.shape[0]*100),1) print (f&quot;--&gt; percentage of negative tweets: {negativetweets} %&quot;) . --&gt; percentage of negative tweets: 14.4 % . df_text[&#39;analysis&#39;].value_counts() #plot and visualize the counts plt.title(&#39;Sentiment Analysis&#39;) plt.xlabel(&#39;Sentiment&#39;) plt.ylabel(&#39;Counts&#39;) df_text[&#39;analysis&#39;].value_counts().plot(kind=&#39;bar&#39;) plt.show(&#39;Sentiment&#39;) . B- Word Level Analysis . B.1 Define Tokenized Tweets . import nltk nltk.download(&#39;punkt&#39;) nltk.download(&#39;stopwords&#39;) . [nltk_data] Downloading package punkt to [nltk_data] C: Users Sara AppData Roaming nltk_data... [nltk_data] Package punkt is already up-to-date! [nltk_data] Downloading package stopwords to [nltk_data] C: Users Sara AppData Roaming nltk_data... [nltk_data] Unzipping corpora stopwords.zip. . True . from nltk.corpus import stopwords # nltk.download(&#39;stopwords&#39;) #need to run on a new machine import ast #used for literal_eval . ## split content into words df_text[&#39;tokenized_tw&#39;] = df_text.apply(lambda row: nltk.word_tokenize(row[&#39;text&#39;]), axis=1) # df_text[&#39;tokenized_tw&#39;] = df_text[&#39;tokenized_tw&#39;].tolist() . df_text = df_text.apply(lambda x: x.astype(str).str.lower()) df_text.head(1) . text created_at place hashtags subjectivity polarity analysis tokenized_tw . 0 what have ive been up to washing my hands soci... | thu mar 26 22:45:10 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.5333333333333333 | 0.016666666666666666 | positive | [&#39;what&#39;, &#39;have&#39;, &#39;ive&#39;, &#39;been&#39;, &#39;up&#39;, &#39;to&#39;, &#39;w... | . B.2 Apply Filters - Find/Remove Stopwords . # stop_words = stopwords.words(&#39;english&#39;) # check what is included here # stop_words . df_text.head(2) type(df_text[&#39;tokenized_tw&#39;]) . pandas.core.series.Series . def remove_stopwords(TokenList): # x = &#39;[ &quot;A&quot;,&quot;B&quot;,&quot;C&quot; , &quot; D&quot;]&#39; # TokenList = str(TokenList) # Identify StopWords - get them from stopwords stop_words = stopwords.words(&#39;english&#39;) # convert string value to a list if isinstance(TokenList, str): TokenList = ast.literal_eval(TokenList) # TokenList = TokenList.split(&quot;,&quot;) for i, key in enumerate(TokenList): if (key in stop_words): TokenList [i] = &#39;&#39; return TokenList # df_text[&#39;tokenized_tw&#39;] = df_text[&#39;tokenized_tw&#39;].apply(lambda x: [item for item in x if item not in stop_words]) # df_text[&#39;tokenized_tw&#39;] = df_text[&#39;tokenized_tw&#39;].apply(lambda x: [item for item in str(x).split(&#39;,&#39;) if (item not in stop_words)]) nRecords = df_text[&#39;tokenized_tw&#39;].count() # nRecords = 3 # if the tokenized column is string change it to list for x in range(nRecords): if (isinstance(df_text[&#39;tokenized_tw&#39;][x],str)): # tokenListHere = df_text[&#39;tokenized_tw&#39;][0].split(&quot;,&quot;) df_text[&#39;tokenized_tw&#39;][x] = remove_stopwords(df_text[&#39;tokenized_tw&#39;][x]) # df_text[&#39;tokenized_tw&#39;] = df_text[&#39;tokenized_tw&#39;].apply(lambda x: [item for item in str(x).split(&#39;,&#39;) if (item not in stop_words)]) # df_text[&#39;tokenized_tw&#39;][0] = remove_stopwords(df_text[&#39;tokenized_tw&#39;][0]) # df_text[&#39;tokenized_tw&#39;][0] = remove_stopwords(df_text[&#39;tokenized_tw&#39;][0]) # df_text[&#39;tokenized_tw&#39;] = df_text[&#39;tokenized_tw&#39;].apply(remove_stopwords) # for x in range(nRecords-1): # df_text[&#39;tokenized_tw&#39;][x] = remove_stopwords(df_text[&#39;tokenized_tw&#39;][x]) # df_text[&#39;tokenized_tw&#39;] = df_text[&#39;tokenized_tw&#39;].apply(remove_stopwords) # TokenList = [&#39;method&#39;,&#39;is&#39;, &#39;toronto&#39;,&#39;and&#39;] # TokenList = remove_stopwords(TokenList) # TokenList . # df_text[&#39;tokenized_tw&#39;] = df_text[&#39;tokenized_tw&#39;].apply(lambda x: [item for item in str(x).split() if len(x) &gt; 2]) df_text.head(2) . text created_at place hashtags subjectivity polarity analysis tokenized_tw . 0 what have ive been up to washing my hands soci... | thu mar 26 22:45:10 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.5333333333333333 | 0.016666666666666666 | positive | [, , ive, , , , washing, , hands, social, dist... | . 1 alarm highrise residential north yorklawrence ... | fri mar 20 13:22:05 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.0 | 0.0 | neutral | [alarm, highrise, residential, north, yorklawr... | . B.2 Apply Filters - stemming words . from nltk.stem.porter import PorterStemmer . def applyporter(TokenList): # create an object for stemming porterstemmer = PorterStemmer() # TokenList = ast.literal_eval(TokenList) if isinstance(TokenList, str): TokenList = TokenList.split(&quot;,&quot;) for i, key in enumerate(TokenList): TokenList [i] = porterstemmer.stem(key) return TokenList # tokens = word_tokenize(text) nRecords = df_text[&#39;tokenized_tw&#39;].count() # apply porterstemmer on tokens for x in range(nRecords-1): df_text[&#39;tokenized_tw&#39;][x] = applyporter(df_text[&#39;tokenized_tw&#39;][x]) . df_text.head(2) . text created_at place hashtags subjectivity polarity analysis tokenized_tw . 0 what have ive been up to washing my hands soci... | thu mar 26 22:45:10 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.5333333333333333 | 0.016666666666666666 | positive | [, , ive, , , , wash, , hand, social, distanc,... | . 1 alarm highrise residential north yorklawrence ... | fri mar 20 13:22:05 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.0 | 0.0 | neutral | [alarm, highris, residenti, north, yorklawr, a... | . Return the cleaned data into a sentence format . for i in range(nRecords): if isinstance(df_text[&#39;tokenized_tw&#39;][i],list): df_text[&#39;tokenized_tw&#39;][i] = &quot; &quot;.join(df_text[&#39;tokenized_tw&#39;][i]) df_text.head(10) . text created_at place hashtags subjectivity polarity analysis tokenized_tw . 0 what have ive been up to washing my hands soci... | thu mar 26 22:45:10 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.5333333333333333 | 0.016666666666666666 | positive | ive wash hand social distanc self isol ... | . 1 alarm highrise residential north yorklawrence ... | fri mar 20 13:22:05 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.0 | 0.0 | neutral | alarm highris residenti north yorklawr avenu c... | . 2 how rdh and myself pass people when we see the... | thu mar 26 02:04:15 +0000 2020 | toronto, ontario | btpent dttheartist toronto artistlife isignmys... | 0.0 | 0.0 | neutral | rdh pass peopl see corona viru quarant... | . 3 life b corona canada | wed mar 25 20:11:32 +0000 2020 | toronto, ontario | corona | 0.0 | 0.0 | neutral | life b corona canada | . 4 lets all be brave and stay at home yeah stayho... | wed mar 25 03:29:35 +0000 2020 | toronto, ontario | stayhome covid_19 corona coronamemes quotes se... | 1.0 | 0.8 | positive | let brave stay home yeah stayhom corona co... | . 5 sending love wherever its needed uponoccasion ... | mon mar 23 13:22:42 +0000 2020 | toronto, ontario | uponoccasion uponoccasionevents sendinglove lo... | 0.6 | 0.5 | positive | send love wherev need uponoccas uponoccasione... | . 6 thursday night corona time isolated floors up... | fri mar 20 01:00:28 +0000 2020 | toronto, ontario | netflix amazonprime tequila donjulio70 hope li... | 1.0 | -0.5 | negative | thursday night corona time isol floor bore a... | . 7 shibani kashyaps new tune corona ko hai harana... | sat mar 28 16:27:32 +0000 2020 | brampton, ontario | entertainment entertainmentmusic | 0.6772727272727272 | 0.36818181818181817 | positive | shibani kashyap new tune corona ko hai harana ... | . 8 people in are annoyed by this opera singer gi... | tue mar 24 18:22:20 +0000 2020 | toronto, ontario | covid_19 socialdistancing coronavirus corona f... | 0.8 | -0.4 | negative | peopl annoy opera singer give perform ba... | . 9 hey hey hey mfittiesbc before corona d so wan... | mon mar 30 16:22:29 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.7 | -0.4 | negative | hey hey hey mfittiesbc corona wan na see ... | . Create a WordCloud from cleaned tweets . allWords = &#39; &#39;.join(twts for twts in df_text[&#39;tokenized_tw&#39;]) wordCloud = WordCloud(width=800, height=500, random_state=21,max_font_size=119).generate(allWords) # size the plt object plt.figure(figsize=(19,8)) plt.imshow(wordCloud, interpolation= &#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.show() . Consider Location and Time in analysis . df_text.groupby([&#39;place&#39;]).count . &lt;bound method DataFrameGroupBy.count of &lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000023EB33975B0&gt;&gt; . from datetime import datetime from dateutil.parser import parse . df_text[&#39;date&#39;] = df_text[&#39;created_at&#39;] # Add a new column for date and convert created_at field for x in range(nRecords): # return date as Series df_text[&#39;date&#39;][x] = datetime.strptime(df_text[&#39;created_at&#39;][x],&#39;%a %b %d %H:%M:%S +0000 %Y&#39;) # return date as a string # df_text[&#39;date&#39;][x] = datetime.strftime(datetime.strptime(df_text[&#39;created_at&#39;][x],&#39;%a %b %d %H:%M:%S +0000 %Y&#39;), &#39;%Y-%m-%d %H:%M:%S&#39;) # Extract month from the data variable, Add a new column df_text[&#39;month&#39;] = pd.DatetimeIndex(df_text[&#39;date&#39;]).month . df_text. head(3) . text created_at place hashtags subjectivity polarity analysis tokenized_tw date month . 0 what have ive been up to washing my hands soci... | thu mar 26 22:45:10 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.5333333333333333 | 0.016666666666666666 | positive | ive wash hand social distanc self isol ... | 2020-03-26 22:45:10 | 3 | . 1 alarm highrise residential north yorklawrence ... | fri mar 20 13:22:05 +0000 2020 | toronto, ontario | &lt;na&gt; | 0.0 | 0.0 | neutral | alarm highris residenti north yorklawr avenu c... | 2020-03-20 13:22:05 | 3 | . 2 how rdh and myself pass people when we see the... | thu mar 26 02:04:15 +0000 2020 | toronto, ontario | btpent dttheartist toronto artistlife isignmys... | 0.0 | 0.0 | neutral | rdh pass peopl see corona viru quarant... | 2020-03-26 02:04:15 | 3 | . Data preparation for further visualizations . # Group by place # placesRecords = df_text.groupby([&#39;place&#39;]) # get the first item in each place group # placesRecords.first() # remove ontario from place column lista = df_text.place.str.split(&quot;,&quot;,expand=True) df_text[&#39;place&#39;] = lista [0] # convert the polarity and subjectivity values to numbers df_text[&quot;polarity&quot;] = pd.to_numeric(df_text[&#39;polarity&#39;]) df_text[&quot;subjectivity&quot;] = pd.to_numeric(df_text[&#39;subjectivity&#39;]) # create new dataframes for further visualizations # get number of tweets from each place df_region_sentiment = df_text.groupby(&#39;place&#39;, as_index=False)[&#39;polarity&#39;].mean() # get the polarities and months information df_time_sentiment = df_text.groupby(&#39;month&#39;, as_index=False)[&#39;polarity&#39;].mean() . df_region_sentiment.head(5) # df_region_sentiment.sort_values(by=&#39;polarity&#39;) . place polarity . 0 &lt;na&gt; | 0.146667 | . 1 ajax | 0.198292 | . 2 aurora | 0.225217 | . 3 barrie | 0.258013 | . 4 bradford west gwillimbury | 0.004408 | . #df_region_sentiment[&quot;polarity&quot;] = pd.to_numeric(df_region_sentiment[&#39;polarity&#39;]) df_region_sentiment.sort_values(by=&#39;polarity&#39;).plot.barh(x=&#39;place&#39;, y=&#39;polarity&#39;, rot=0, figsize=(15, 10)) . &lt;AxesSubplot:ylabel=&#39;place&#39;&gt; . df_time_sentiment.head(5) . month polarity . 0 3 | 0.121948 | . 1 4 | 0.117046 | . 2 5 | 0.137847 | . 3 6 | 0.120448 | . 4 7 | 0.105503 | . df_time_sentiment.sort_values(by=&#39;month&#39;).plot.line(x=&#39;month&#39;, y=&#39;polarity&#39;, rot=0, figsize=(15, 10), color=&quot;blue&quot;) . &lt;AxesSubplot:xlabel=&#39;month&#39;&gt; .",
            "url": "https://sra00.github.io/notebookposts/2021/11/09/tw2.html",
            "relUrl": "/2021/11/09/tw2.html",
            "date": " ‚Ä¢ Nov 9, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Tweets Sentiment analysis",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . import pandas as pd import numpy as np import re from textblob import TextBlob from wordcloud import WordCloud import matplotlib.pyplot as plt plt.style.use(&#39;fivethirtyeight&#39;) toronto_df = pd.read_csv(&quot;textdata/Toronto-dataset.csv&quot;) . . . # toronto_df.head(5) #df_text = toronto_df[&#39;text&#39;] . Get the overall info from the dataset . df_text = toronto_df[[&#39;text&#39;]].convert_dtypes(object,str) ## Perhaps we need the hashtags too #df_text = toronto_df[[&#39;hashtags&#39;,&#39;text&#39;]] . Cleaning the text Data . def cleanEmoji(text): regrex_pattern = re.compile(pattern = &quot;[&quot; u&quot; U0001F600- U0001F64F&quot; # emoticons u&quot; U0001F300- U0001F5FF&quot; # symbols &amp; pictographs u&quot; U0001F680- U0001F6FF&quot; # transport &amp; map symbols u&quot; U0001F1E0- U0001F1FF&quot; # flags (iOS) u&quot; U00002702- U000027B0&quot; u&quot; U000024C2- U0001F251&quot; &quot;]+&quot;, flags = re.UNICODE) return regrex_pattern.sub(r&#39;&#39;,text) #2-CleanTweets function replaces non-text entities with space def cleanTweets(text): text = re.sub(r&#39;@[A-Za-z0-9]&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove @mentions text = re.sub(r&#39;#&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Removing the # symbol text = re.sub(r&#39;@&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Removing the # symbol text = re.sub(r&#39;RT[ s]+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove RT text = re.sub(r&#39;https?: / / S+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove the hyper link text = re.sub(r&#39;http?: / / S+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove the hyper link text = re.sub(r&#39;^https?: / /.*[ r n]*&#39;, &#39;&#39;, text, flags=re.MULTILINE) #text = re.sub(&#39;https&#39;, &#39;&#39;, text, flags=re.MULTILINE) #text = re.sub(&#39;https&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;urbanstreetphotography&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;cityscape&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;streetphotographer&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;urbanstreetphotogallery&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;photodocumentary&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;ig_street&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Covid&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;COVID&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;covid&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;spicollective&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Spicollective&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;lensculture&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;bnw&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;BNW&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;BW&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;bw&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(r&#39; xc2 xb7&#39;,&#39;&#39;,text) # Remove bullet points text = re.sub(r&#39; u2022&#39;,&#39;&#39;,text) # Remove bullet points # text = re.sub(r&#39;https?: / /(www .)?[-a-zA-Z0‚Äì9@:%._ +~#=]{2,256} .[a-z]{2,6} b([-a-zA-Z0‚Äì9@:%_ +.~#?&amp;//=]*)&#39;, # &#39;&#39;, text, flags=re.MULTILINE) # Remove links that start with HTTP/HTTPS in the tweet # text = re.sub(r&#39;[-a-zA-Z0‚Äì9@:%._ +~#=]{2,256} .[a-z]{2,6} b([-a-zA-Z0‚Äì9@:%_ +.~#?&amp;//=]*)&#39;, # &#39;&#39;, text, flags=re.MULTILINE) # Remove other url links return text . # s = df_text.iloc[[2]] df_text = toronto_df[[&#39;text&#39;]].convert_dtypes(object,str) df_text[&#39;text&#39;] = df_text[&#39;text&#39;].apply(cleanTweets) df_text[&#39;text&#39;] = df_text[&#39;text&#39;].apply(cleanEmoji) #df_text . Start working on the contect and subject area . def getSubjectivity(text): return TextBlob(text).sentiment.subjectivity #create a function to get the polarity def getPolarity(text): return TextBlob(text).sentiment.polarity #Create two new columns to add the sentiment and polarity df_text[&#39;subjectivity&#39;] = df_text[&#39;text&#39;].apply(getSubjectivity) df_text[&#39;polarity&#39;] = df_text[&#39;text&#39;].apply(getPolarity) #Display the new dataset #df_text . allWords = &#39; &#39;.join(twts for twts in df_text[&#39;text&#39;]) wordCloud = WordCloud(width=500, height=300, random_state=21,max_font_size=119).generate(allWords) plt.imshow(wordCloud, interpolation= &#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.show() . def getSentAnalysis(score): if score &lt; 0: return &quot;Negative&quot; elif score == 0: return &#39;Neutral&#39; else: return &#39;Positive&#39; df_text[&#39;analysis&#39;] = df_text[&#39;polarity&#39;].apply(getSentAnalysis) #df_text . j=1 sortedDF_text = df_text.sort_values(by=[&#39;polarity&#39;]) for i in range(0, sortedDF_text.shape[0]): if (sortedDF_text[&#39;analysis&#39;][i] == &#39;Positive&#39;): #print(str(j)+ &#39;)&#39; + sortedDF_text[&#39;text&#39;][i]) #print() j = j+1 . plt.figure(figsize=(8,6)) for i in range(0,df_text.shape[0]): plt.scatter(df_text[&#39;polarity&#39;][i],df_text[&#39;subjectivity&#39;][i], color=&#39;Blue&#39;) plt.title(&#39;Sentiment Analysis&#39;) plt.xlabel(&#39;Polarity&#39;) plt.xlabel(&#39;Subjectivity&#39;) plt.show() . ptweets = df_text[df_text.analysis == &#39;Positive&#39;] ptweets = ptweets [&#39;text&#39;] round ((ptweets.shape[0] /df_text.shape[0]) *100,1) . 51.5 . ntweets = df_text[df_text.analysis == &#39;Negative&#39;] ntweets = ntweets[&#39;text&#39;] round( (ntweets.shape[0] / df_text.shape[0]*100),1) . 14.0 . df_text[&#39;analysis&#39;].value_counts() #plot and visualize the counts plt.title(&#39;Sentiment Analysis&#39;) plt.xlabel(&#39;Sentiment&#39;) plt.ylabel(&#39;Counts&#39;) df_text[&#39;analysis&#39;].value_counts().plot(kind=&#39;bar&#39;) plt.show(&#39;Sentiment&#39;) .",
            "url": "https://sra00.github.io/notebookposts/tweetanalysis/2021/11/09/tw1.html",
            "relUrl": "/tweetanalysis/2021/11/09/tw1.html",
            "date": " ‚Ä¢ Nov 9, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://sra00.github.io/notebookposts/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " ‚Ä¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a ‚Äúlevel 1 heading‚Äù in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here‚Äôs a footnote 1. Here‚Äôs a horizontal rule: . . Lists . Here‚Äôs a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes ‚Ä¶and‚Ä¶ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.¬†&#8617; . |",
            "url": "https://sra00.github.io/notebookposts/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " ‚Ä¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://sra00.github.io/notebookposts/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://sra00.github.io/notebookposts/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}