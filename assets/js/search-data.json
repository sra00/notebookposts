{
  
    
        "post0": {
            "title": "Tweets Sentiment analysis",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . import pandas as pd import numpy as np import re from textblob import TextBlob from wordcloud import WordCloud import matplotlib.pyplot as plt plt.style.use(&#39;fivethirtyeight&#39;) toronto_df = pd.read_csv(&quot;textdata/Toronto-dataset.csv&quot;) . . . # toronto_df.head(5) #df_text = toronto_df[&#39;text&#39;] . Get the overall info from the dataset . df_text = toronto_df[[&#39;text&#39;]].convert_dtypes(object,str) ## Perhaps we need the hashtags too #df_text = toronto_df[[&#39;hashtags&#39;,&#39;text&#39;]] . Cleaning the text Data . def cleanEmoji(text): regrex_pattern = re.compile(pattern = &quot;[&quot; u&quot; U0001F600- U0001F64F&quot; # emoticons u&quot; U0001F300- U0001F5FF&quot; # symbols &amp; pictographs u&quot; U0001F680- U0001F6FF&quot; # transport &amp; map symbols u&quot; U0001F1E0- U0001F1FF&quot; # flags (iOS) u&quot; U00002702- U000027B0&quot; u&quot; U000024C2- U0001F251&quot; &quot;]+&quot;, flags = re.UNICODE) return regrex_pattern.sub(r&#39;&#39;,text) #2-CleanTweets function replaces non-text entities with space def cleanTweets(text): text = re.sub(r&#39;@[A-Za-z0-9]&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove @mentions text = re.sub(r&#39;#&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Removing the # symbol text = re.sub(r&#39;@&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Removing the # symbol text = re.sub(r&#39;RT[ s]+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove RT text = re.sub(r&#39;https?: / / S+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove the hyper link text = re.sub(r&#39;http?: / / S+&#39;,&#39;&#39;,text, flags=re.MULTILINE) # Remove the hyper link text = re.sub(r&#39;^https?: / /.*[ r n]*&#39;, &#39;&#39;, text, flags=re.MULTILINE) #text = re.sub(&#39;https&#39;, &#39;&#39;, text, flags=re.MULTILINE) #text = re.sub(&#39;https&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;urbanstreetphotography&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;cityscape&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;streetphotographer&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;urbanstreetphotogallery&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;photodocumentary&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;ig_street&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Covid&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;COVID&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;covid&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;spicollective&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Spicollective&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;lensculture&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Toronto&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(&#39;Ontario&#39;, &#39;&#39;, text, flags=re.MULTILINE) text = re.sub(r&#39; xc2 xb7&#39;,&#39;&#39;,text) # Remove bullet points text = re.sub(r&#39; u2022&#39;,&#39;&#39;,text) # Remove bullet points # text = re.sub(r&#39;https?: / /(www .)?[-a-zA-Z0–9@:%._ +~#=]{2,256} .[a-z]{2,6} b([-a-zA-Z0–9@:%_ +.~#?&amp;//=]*)&#39;, # &#39;&#39;, text, flags=re.MULTILINE) # Remove links that start with HTTP/HTTPS in the tweet # text = re.sub(r&#39;[-a-zA-Z0–9@:%._ +~#=]{2,256} .[a-z]{2,6} b([-a-zA-Z0–9@:%_ +.~#?&amp;//=]*)&#39;, # &#39;&#39;, text, flags=re.MULTILINE) # Remove other url links return text . # s = df_text.iloc[[2]] df_text = toronto_df[[&#39;text&#39;]].convert_dtypes(object,str) df_text[&#39;text&#39;] = df_text[&#39;text&#39;].apply(cleanTweets) df_text[&#39;text&#39;] = df_text[&#39;text&#39;].apply(cleanEmoji) #df_text . Start working on the contect and subject area . def getSubjectivity(text): return TextBlob(text).sentiment.subjectivity #create a function to get the polarity def getPolarity(text): return TextBlob(text).sentiment.polarity #Create two new columns to add the sentiment and polarity df_text[&#39;subjectivity&#39;] = df_text[&#39;text&#39;].apply(getSubjectivity) df_text[&#39;polarity&#39;] = df_text[&#39;text&#39;].apply(getPolarity) #Display the new dataset #df_text . allWords = &#39; &#39;.join(twts for twts in df_text[&#39;text&#39;]) wordCloud = WordCloud(width=500, height=300, random_state=21,max_font_size=119).generate(allWords) plt.imshow(wordCloud, interpolation= &#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.show() . def getSentAnalysis(score): if score &lt; 0: return &quot;Negative&quot; elif score == 0: return &#39;Neutral&#39; else: return &#39;Positive&#39; df_text[&#39;analysis&#39;] = df_text[&#39;polarity&#39;].apply(getSentAnalysis) #df_text . j=1 sortedDF_text = df_text.sort_values(by=[&#39;polarity&#39;]) for i in range(0, sortedDF_text.shape[0]): if (sortedDF_text[&#39;analysis&#39;][i] == &#39;Positive&#39;): #print(str(j)+ &#39;)&#39; + sortedDF_text[&#39;text&#39;][i]) #print() j = j+1 . plt.figure(figsize=(8,6)) for i in range(0,df_text.shape[0]): plt.scatter(df_text[&#39;polarity&#39;][i],df_text[&#39;subjectivity&#39;][i], color=&#39;Blue&#39;) plt.title(&#39;Sentiment Analysis&#39;) plt.xlabel(&#39;Polarity&#39;) plt.xlabel(&#39;Subjectivity&#39;) plt.show() . ptweets = df_text[df_text.analysis == &#39;Positive&#39;] ptweets = ptweets [&#39;text&#39;] round ((ptweets.shape[0] /df_text.shape[0]) *100,1) . 51.5 . ntweets = df_text[df_text.analysis == &#39;Negative&#39;] ntweets = ntweets[&#39;text&#39;] round( (ntweets.shape[0] / df_text.shape[0]*100),1) . 14.0 . df_text[&#39;analysis&#39;].value_counts() #plot and visualize the counts plt.title(&#39;Sentiment Analysis&#39;) plt.xlabel(&#39;Sentiment&#39;) plt.ylabel(&#39;Counts&#39;) df_text[&#39;analysis&#39;].value_counts().plot(kind=&#39;bar&#39;) plt.show(&#39;Sentiment&#39;) .",
            "url": "https://sra00.github.io/notebookposts/tweetanalysis/2021/11/06/tw1.html",
            "relUrl": "/tweetanalysis/2021/11/06/tw1.html",
            "date": " • Nov 6, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "%load_ext autoreload %autoreload 2 %matplotlib inline . . from fastai.imports import * from fastai.tabular import * import fastai.tabular.core from fastai.data.all import * import fastai.torch_core from pandas_summary import DataFrameSummary from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier from IPython.display import display from sklearn import metrics from pandas import DatetimeIndex . %load &quot;fastai/structured.py&quot; %run &quot;fastai/structured.py&quot; . PATH = &quot;data/bulldozers/&quot; . {PATH} . {&#39;data/bulldozers/&#39;} . df_raw = pd.read_csv(f&#39;{PATH}Train.csv&#39;,low_memory=False,parse_dates=[&quot;saledate&quot;]) . df_raw . SalesID SalePrice MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter UsageBand saledate ... Undercarriage_Pad_Width Stick_Length Thumb Pattern_Changer Grouser_Type Backhoe_Mounting Blade_Type Travel_Controls Differential_Type Steering_Controls . 0 1139246 | 66000 | 999089 | 3157 | 121 | 3.0 | 2004 | 68.0 | Low | 2006-11-16 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Standard | Conventional | . 1 1139248 | 57000 | 117657 | 77 | 121 | 3.0 | 1996 | 4640.0 | Low | 2004-03-26 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | Standard | Conventional | . 2 1139249 | 10000 | 434808 | 7009 | 121 | 3.0 | 2001 | 2838.0 | High | 2004-02-26 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 3 1139251 | 38500 | 1026470 | 332 | 121 | 3.0 | 2001 | 3486.0 | High | 2011-05-19 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 4 1139253 | 11000 | 1057373 | 17311 | 121 | 3.0 | 2007 | 722.0 | Medium | 2009-07-23 | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 401120 6333336 | 10500 | 1840702 | 21439 | 149 | 1.0 | 2005 | NaN | NaN | 2011-11-02 | ... | None or Unspecified | None or Unspecified | None or Unspecified | None or Unspecified | Double | NaN | NaN | NaN | NaN | NaN | . 401121 6333337 | 11000 | 1830472 | 21439 | 149 | 1.0 | 2005 | NaN | NaN | 2011-11-02 | ... | None or Unspecified | None or Unspecified | None or Unspecified | None or Unspecified | Double | NaN | NaN | NaN | NaN | NaN | . 401122 6333338 | 11500 | 1887659 | 21439 | 149 | 1.0 | 2005 | NaN | NaN | 2011-11-02 | ... | None or Unspecified | None or Unspecified | None or Unspecified | None or Unspecified | Double | NaN | NaN | NaN | NaN | NaN | . 401123 6333341 | 9000 | 1903570 | 21435 | 149 | 2.0 | 2005 | NaN | NaN | 2011-10-25 | ... | None or Unspecified | None or Unspecified | None or Unspecified | None or Unspecified | Double | NaN | NaN | NaN | NaN | NaN | . 401124 6333342 | 7750 | 1926965 | 21435 | 149 | 2.0 | 2005 | NaN | NaN | 2011-10-25 | ... | None or Unspecified | None or Unspecified | None or Unspecified | None or Unspecified | Double | NaN | NaN | NaN | NaN | NaN | . 401125 rows × 53 columns . #log(x) is natural logarithm of x - logs is a simpler way o express larges values df_raw[&#39;SalePrice&#39;] = np. log(df_raw.SalePrice) . df_raw.SalePrice . 0 11.097410 1 10.950807 2 9.210340 3 10.558414 4 9.305651 ... 401120 9.259131 401121 9.305651 401122 9.350102 401123 9.104980 401124 8.955448 Name: SalePrice, Length: 401125, dtype: float64 . df_raw.saledate.head() . 0 2006-11-16 1 2004-03-26 2 2004-02-26 3 2011-05-19 4 2009-07-23 Name: saledate, dtype: datetime64[ns] . . fld = df_raw.saledate . . # df_raw[&#39;saleYear&#39;] = df_raw[&#39;saledate&#39;].dt.year # df_raw[&#39;saleMonth&#39;] = df_raw[&#39;saledate&#39;].dt.month # df_raw[&#39;saleWeek&#39;] = df_raw[&#39;saledate&#39;].dt.week # df_raw[&#39;saleDay&#39;] = df_raw[&#39;saledate&#39;].dt.day # Series.dt.isocalendar().week # df_raw = df_raw.drop(&#39;saleYear&#39;, 1) #df_raw.columns . fastai.tabular.core.add_datepart(df_raw,&#39;saledate&#39;) df_raw.saleYear.head() . 0 2006 1 2004 2 2004 3 2011 4 2009 Name: saleYear, dtype: int64 . df_raw.columns . Index([&#39;SalesID&#39;, &#39;SalePrice&#39;, &#39;MachineID&#39;, &#39;ModelID&#39;, &#39;datasource&#39;, &#39;auctioneerID&#39;, &#39;YearMade&#39;, &#39;MachineHoursCurrentMeter&#39;, &#39;UsageBand&#39;, &#39;fiModelDesc&#39;, &#39;fiBaseModel&#39;, &#39;fiSecondaryDesc&#39;, &#39;fiModelSeries&#39;, &#39;fiModelDescriptor&#39;, &#39;ProductSize&#39;, &#39;fiProductClassDesc&#39;, &#39;state&#39;, &#39;ProductGroup&#39;, &#39;ProductGroupDesc&#39;, &#39;Drive_System&#39;, &#39;Enclosure&#39;, &#39;Forks&#39;, &#39;Pad_Type&#39;, &#39;Ride_Control&#39;, &#39;Stick&#39;, &#39;Transmission&#39;, &#39;Turbocharged&#39;, &#39;Blade_Extension&#39;, &#39;Blade_Width&#39;, &#39;Enclosure_Type&#39;, &#39;Engine_Horsepower&#39;, &#39;Hydraulics&#39;, &#39;Pushblock&#39;, &#39;Ripper&#39;, &#39;Scarifier&#39;, &#39;Tip_Control&#39;, &#39;Tire_Size&#39;, &#39;Coupler&#39;, &#39;Coupler_System&#39;, &#39;Grouser_Tracks&#39;, &#39;Hydraulics_Flow&#39;, &#39;Track_Type&#39;, &#39;Undercarriage_Pad_Width&#39;, &#39;Stick_Length&#39;, &#39;Thumb&#39;, &#39;Pattern_Changer&#39;, &#39;Grouser_Type&#39;, &#39;Backhoe_Mounting&#39;, &#39;Blade_Type&#39;, &#39;Travel_Controls&#39;, &#39;Differential_Type&#39;, &#39;Steering_Controls&#39;, &#39;saleYear&#39;, &#39;saleMonth&#39;, &#39;saleWeek&#39;, &#39;saleDay&#39;, &#39;saleDayofweek&#39;, &#39;saleDayofyear&#39;, &#39;saleIs_month_end&#39;, &#39;saleIs_month_start&#39;, &#39;saleIs_quarter_end&#39;, &#39;saleIs_quarter_start&#39;, &#39;saleIs_year_end&#39;, &#39;saleIs_year_start&#39;, &#39;saleElapsed&#39;], dtype=&#39;object&#39;) . m = RandomForestRegressor(n_jobs = -1) m.fit(df_raw.drop(&#39;SalePrice&#39;,axis=1), df_raw.SalePrice) . ValueError Traceback (most recent call last) &lt;ipython-input-82-bc6c00665d73&gt; in &lt;module&gt; 1 #Apply Randon Forest 2 m = RandomForestRegressor(n_jobs = -1) -&gt; 3 m.fit(df_raw.drop(&#39;SalePrice&#39;,axis=1), df_raw.SalePrice) C: Programs Python Python39 lib site-packages sklearn ensemble _forest.py in fit(self, X, y, sample_weight) 302 &#34;sparse multilabel-indicator for y is not supported.&#34; 303 ) --&gt; 304 X, y = self._validate_data(X, y, multi_output=True, 305 accept_sparse=&#34;csc&#34;, dtype=DTYPE) 306 if sample_weight is not None: C: Programs Python Python39 lib site-packages sklearn base.py in _validate_data(self, X, y, reset, validate_separately, **check_params) 431 y = check_array(y, **check_y_params) 432 else: --&gt; 433 X, y = check_X_y(X, y, **check_params) 434 out = X, y 435 C: Programs Python Python39 lib site-packages sklearn utils validation.py in inner_f(*args, **kwargs) 61 extra_args = len(args) - len(all_args) 62 if extra_args &lt;= 0: &gt; 63 return f(*args, **kwargs) 64 65 # extra_args &gt; 0 C: Programs Python Python39 lib site-packages sklearn utils validation.py in check_X_y(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator) 869 raise ValueError(&#34;y cannot be None&#34;) 870 --&gt; 871 X = check_array(X, accept_sparse=accept_sparse, 872 accept_large_sparse=accept_large_sparse, 873 dtype=dtype, order=order, copy=copy, C: Programs Python Python39 lib site-packages sklearn utils validation.py in inner_f(*args, **kwargs) 61 extra_args = len(args) - len(all_args) 62 if extra_args &lt;= 0: &gt; 63 return f(*args, **kwargs) 64 65 # extra_args &gt; 0 C: Programs Python Python39 lib site-packages sklearn utils validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator) 671 array = array.astype(dtype, casting=&#34;unsafe&#34;, copy=False) 672 else: --&gt; 673 array = np.asarray(array, order=order, dtype=dtype) 674 except ComplexWarning as complex_warning: 675 raise ValueError(&#34;Complex data not supported n&#34; C: Programs Python Python39 lib site-packages numpy core _asarray.py in asarray(a, dtype, order, like) 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like) 101 --&gt; 102 return array(a, dtype, copy=False, order=order) 103 104 C: Programs Python Python39 lib site-packages pandas core generic.py in __array__(self, dtype) 1897 1898 def __array__(self, dtype=None) -&gt; np.ndarray: -&gt; 1899 return np.asarray(self._values, dtype=dtype) 1900 1901 def __array_wrap__( C: Programs Python Python39 lib site-packages numpy core _asarray.py in asarray(a, dtype, order, like) 100 return _asarray_with_like(a, dtype=dtype, order=order, like=like) 101 --&gt; 102 return array(a, dtype, copy=False, order=order) 103 104 ValueError: could not convert string to float: &#39;Low&#39; . # the numeric coding required for a random forest. Therefore we call train_cats to convert strinf tp pandas categries.False . #python has something like this too # no change will be seen in the dataframe, it is in the background train_cats(df_raw) . df_raw.head() . SalesID SalePrice MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter UsageBand fiModelDesc ... saleDay saleDayofweek saleDayofyear saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed . 0 1139246 | 11.097410 | 999089 | 3157 | 121 | 3.0 | 2004 | 68.0 | Low | 521D | ... | 16 | 3 | 320 | False | False | False | False | False | False | 1.163635e+09 | . 1 1139248 | 10.950807 | 117657 | 77 | 121 | 3.0 | 1996 | 4640.0 | Low | 950FII | ... | 26 | 4 | 86 | False | False | False | False | False | False | 1.080259e+09 | . 2 1139249 | 9.210340 | 434808 | 7009 | 121 | 3.0 | 2001 | 2838.0 | High | 226 | ... | 26 | 3 | 57 | False | False | False | False | False | False | 1.077754e+09 | . 3 1139251 | 10.558414 | 1026470 | 332 | 121 | 3.0 | 2001 | 3486.0 | High | PC120-6E | ... | 19 | 3 | 139 | False | False | False | False | False | False | 1.305763e+09 | . 4 1139253 | 9.305651 | 1057373 | 17311 | 121 | 3.0 | 2007 | 722.0 | Medium | S175 | ... | 23 | 3 | 204 | False | False | False | False | False | False | 1.248307e+09 | . 5 rows × 65 columns . # will treat them as 0 1 2, you df_raw.UsageBand.cat.categories . Index([&#39;High&#39;, &#39;Low&#39;, &#39;Medium&#39;], dtype=&#39;object&#39;) . df_raw.UsageBand.cat.codes . 0 1 1 1 2 0 3 0 4 2 .. 401120 -1 401121 -1 401122 -1 401123 -1 401124 -1 Length: 401125, dtype: int8 . #inplace=True - &gt; Instead of creating a new data frame updatres the same one df_raw.UsageBand.cat.set_categories([&#39;High&#39;,&#39;Medium&#39;,&#39;Low&#39;],ordered=True, inplace=True) #get_dummies makes different columns, this one makes one column . Steps we did so far . 1- we turned the string to numbers -&gt; used datasplit and using cats | 2- Now we need to make sure we have no null | . def display_all(df): with pd.option_context(&quot;display.max_rows&quot;, 1000): with pd.option_context(&quot;display.max_columns&quot;, 1000): display(df) . display_all(df_raw.isnull().sum().sort_index()/len(df_raw)) . Backhoe_Mounting 0.803872 Blade_Extension 0.937129 Blade_Type 0.800977 Blade_Width 0.937129 Coupler 0.466620 Coupler_System 0.891660 Differential_Type 0.826959 Drive_System 0.739829 Enclosure 0.000810 Enclosure_Type 0.937129 Engine_Horsepower 0.937129 Forks 0.521154 Grouser_Tracks 0.891899 Grouser_Type 0.752813 Hydraulics 0.200823 Hydraulics_Flow 0.891899 MachineHoursCurrentMeter 0.644089 MachineID 0.000000 ModelID 0.000000 Pad_Type 0.802720 Pattern_Changer 0.752651 ProductGroup 0.000000 ProductGroupDesc 0.000000 ProductSize 0.525460 Pushblock 0.937129 Ride_Control 0.629527 Ripper 0.740388 SalePrice 0.000000 SalesID 0.000000 Scarifier 0.937102 Steering_Controls 0.827064 Stick 0.802720 Stick_Length 0.752651 Thumb 0.752476 Tip_Control 0.937129 Tire_Size 0.763869 Track_Type 0.752813 Transmission 0.543210 Travel_Controls 0.800975 Turbocharged 0.802720 Undercarriage_Pad_Width 0.751020 UsageBand 0.826391 YearMade 0.000000 auctioneerID 0.050199 datasource 0.000000 fiBaseModel 0.000000 fiModelDesc 0.000000 fiModelDescriptor 0.820707 fiModelSeries 0.858129 fiProductClassDesc 0.000000 fiSecondaryDesc 0.342016 saleDay 0.000000 saleDayofweek 0.000000 saleDayofyear 0.000000 saleElapsed 0.000000 saleIs_month_end 0.000000 saleIs_month_start 0.000000 saleIs_quarter_end 0.000000 saleIs_quarter_start 0.000000 saleIs_year_end 0.000000 saleIs_year_start 0.000000 saleMonth 0.000000 saleWeek 0.000000 saleYear 0.000000 state 0.000000 dtype: float64 . Save the Data . from pyarrow import feather . # we save it in feather format - os.makedirs(&#39;tmp&#39;,exist_ok= True) df_raw.to_feather(&#39;tmp/raw&#39;) . df_raw = pd.read_feather(&#39;tmp/raw&#39;) . df_raw.head() . SalesID SalePrice MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter UsageBand fiModelDesc ... saleDay saleDayofweek saleDayofyear saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed . 0 1139246 | 11.097410 | 999089 | 3157 | 121 | 3.0 | 2004 | 68.0 | Low | 521D | ... | 16 | 3 | 320 | False | False | False | False | False | False | 1.163635e+09 | . 1 1139248 | 10.950807 | 117657 | 77 | 121 | 3.0 | 1996 | 4640.0 | Low | 950FII | ... | 26 | 4 | 86 | False | False | False | False | False | False | 1.080259e+09 | . 2 1139249 | 9.210340 | 434808 | 7009 | 121 | 3.0 | 2001 | 2838.0 | High | 226 | ... | 26 | 3 | 57 | False | False | False | False | False | False | 1.077754e+09 | . 3 1139251 | 10.558414 | 1026470 | 332 | 121 | 3.0 | 2001 | 3486.0 | High | PC120-6E | ... | 19 | 3 | 139 | False | False | False | False | False | False | 1.305763e+09 | . 4 1139253 | 9.305651 | 1057373 | 17311 | 121 | 3.0 | 2007 | 722.0 | Medium | S175 | ... | 23 | 3 | 204 | False | False | False | False | False | False | 1.248307e+09 | . 5 rows × 65 columns . # we&#39;ll replace categories with their numeric codes, handle missing continious values, and split the dependent variable into a separate variable . # actually replace the strings with their numeric codes # pull out the dependet variable SalePrice into a separate variable # handle missing continious valyes-- using proc_df # make a copy of the data frame # drop the dependent variable # fix missing - if numeric -&gt; if does have missing value, create a boolean column 1 anytime missingre # replace the missing with median # for categies - panda sets missing variables to -1 # df, y = proc_df(df_raw,&#39;SalePrice&#39;) . ValueError Traceback (most recent call last) &lt;ipython-input-144-f68b2fa695c9&gt; in &lt;module&gt; 8 # replace the missing with median 9 # for categies - panda sets missing variables to -1 &gt; 10 df, y = proc_df(df_raw,&#39;SalePrice&#39;) ValueError: too many values to unpack (expected 2) . df,x, y = proc_df(df_raw, &#39;SalePrice&#39;) . df.columns . Index([&#39;SalesID&#39;, &#39;MachineID&#39;, &#39;ModelID&#39;, &#39;datasource&#39;, &#39;auctioneerID&#39;, &#39;YearMade&#39;, &#39;MachineHoursCurrentMeter&#39;, &#39;UsageBand&#39;, &#39;fiModelDesc&#39;, &#39;fiBaseModel&#39;, &#39;fiSecondaryDesc&#39;, &#39;fiModelSeries&#39;, &#39;fiModelDescriptor&#39;, &#39;ProductSize&#39;, &#39;fiProductClassDesc&#39;, &#39;state&#39;, &#39;ProductGroup&#39;, &#39;ProductGroupDesc&#39;, &#39;Drive_System&#39;, &#39;Enclosure&#39;, &#39;Forks&#39;, &#39;Pad_Type&#39;, &#39;Ride_Control&#39;, &#39;Stick&#39;, &#39;Transmission&#39;, &#39;Turbocharged&#39;, &#39;Blade_Extension&#39;, &#39;Blade_Width&#39;, &#39;Enclosure_Type&#39;, &#39;Engine_Horsepower&#39;, &#39;Hydraulics&#39;, &#39;Pushblock&#39;, &#39;Ripper&#39;, &#39;Scarifier&#39;, &#39;Tip_Control&#39;, &#39;Tire_Size&#39;, &#39;Coupler&#39;, &#39;Coupler_System&#39;, &#39;Grouser_Tracks&#39;, &#39;Hydraulics_Flow&#39;, &#39;Track_Type&#39;, &#39;Undercarriage_Pad_Width&#39;, &#39;Stick_Length&#39;, &#39;Thumb&#39;, &#39;Pattern_Changer&#39;, &#39;Grouser_Type&#39;, &#39;Backhoe_Mounting&#39;, &#39;Blade_Type&#39;, &#39;Travel_Controls&#39;, &#39;Differential_Type&#39;, &#39;Steering_Controls&#39;, &#39;saleYear&#39;, &#39;saleMonth&#39;, &#39;saleWeek&#39;, &#39;saleDay&#39;, &#39;saleDayofweek&#39;, &#39;saleDayofyear&#39;, &#39;saleIs_month_end&#39;, &#39;saleIs_month_start&#39;, &#39;saleIs_quarter_end&#39;, &#39;saleIs_quarter_start&#39;, &#39;saleIs_year_end&#39;, &#39;saleIs_year_start&#39;, &#39;saleElapsed&#39;, &#39;auctioneerID_na&#39;, &#39;MachineHoursCurrentMeter_na&#39;], dtype=&#39;object&#39;) . df.head() . SalesID MachineID ModelID datasource auctioneerID YearMade MachineHoursCurrentMeter UsageBand fiModelDesc fiBaseModel ... saleDayofyear saleIs_month_end saleIs_month_start saleIs_quarter_end saleIs_quarter_start saleIs_year_end saleIs_year_start saleElapsed auctioneerID_na MachineHoursCurrentMeter_na . 0 1139246 | 999089 | 3157 | 121 | 3.0 | 2004 | 68.0 | 3 | 950 | 296 | ... | 320 | False | False | False | False | False | False | 1.163635e+09 | False | False | . 1 1139248 | 117657 | 77 | 121 | 3.0 | 1996 | 4640.0 | 3 | 1725 | 527 | ... | 86 | False | False | False | False | False | False | 1.080259e+09 | False | False | . 2 1139249 | 434808 | 7009 | 121 | 3.0 | 2001 | 2838.0 | 1 | 331 | 110 | ... | 57 | False | False | False | False | False | False | 1.077754e+09 | False | False | . 3 1139251 | 1026470 | 332 | 121 | 3.0 | 2001 | 3486.0 | 1 | 3674 | 1375 | ... | 139 | False | False | False | False | False | False | 1.305763e+09 | False | False | . 4 1139253 | 1057373 | 17311 | 121 | 3.0 | 2007 | 722.0 | 2 | 4208 | 1529 | ... | 204 | False | False | False | False | False | False | 1.248307e+09 | False | False | . 5 rows × 66 columns . y . {&#39;auctioneerID&#39;: 2.0, &#39;MachineHoursCurrentMeter&#39;: 0.0} . # the score is R square 1 is very good and r is very bad # next we need to use some other dataset to test this m = RandomForestRegressor(n_jobs= -1) m.fit(df,x) m.score(df,x) . 0.9881746598683774 . def split_vals(a,n): return a[:n].copy(), a[n:].copy() n_valid = 12000 # same as Kaggle&#39;s test set size n_trn = len(df)-n_valid raw_train, raw_valid = split_vals(df_raw, n_trn) X_train, X_valid = split_vals(df, n_trn) y_train, y_valid = split_vals(x, n_trn) X_train.shape, y_train.shape, X_valid.shape . ((389125, 66), (389125,), (12000, 66)) . def rmse(x,y): return math.sqrt(((x-y)**2).mean()) def print_score(m): res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid), m.score(X_train, y_train), m.score(X_valid, y_valid)] if hasattr(m, &#39;oob_score_&#39;): res.append(m.oob_score_) print(res) . m = RandomForestRegressor(n_jobs=-1) %time m.fit(X_train, y_train) print_score(m) . Wall time: 1min 37s [0.0756750874062741, 0.2352499050894546, 0.9880314734210563, 0.9011658827282231] . Speeding things up . . df_trn, y_trn, x_trn = proc_df(df_raw,&#39;SalePrice&#39;) X_train, _ = split_vals (df_trn, 20000) y_train, _ = split_vals (y_trn, 20000) . x_trn . {&#39;auctioneerID&#39;: 2.0, &#39;MachineHoursCurrentMeter&#39;: 0.0} . m = RandomForestRegressor(n_jobs= -1) %time m.fit(X_train, y_train) print_score(m) . Wall time: 4.76 s [0.08641229166422504, 0.3221901413038917, 0.9849049040255403, 0.8146159060977014] . Single Tree . m = RandomForestRegressor(n_estimators=1, max_depth=3,bootstrap=False, n_jobs=-1) m.fit(X_train, y_train) print_score(m) . [0.4965829795739235, 0.5246832258551819, 0.5014961773561586, 0.5083655198087903] . import os . # os.environ[&quot;PATH&quot;] += os.pathsep + &#39;C:/Program Files/Graphviz/bin/&#39; . draw_tree(m.estimators_[0], df_trn,precision=3) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; Tree 0 Coupler_System ≤ 0.5 mse = 0.495 samples = 20000 value = 10.189 1 Enclosure ≤ 2.0 mse = 0.414 samples = 16815 value = 10.345 0&#45;&gt;1 True 8 YearMade ≤ 1999.5 mse = 0.109 samples = 3185 value = 9.363 0&#45;&gt;8 False 2 ModelID ≤ 4573.0 mse = 0.331 samples = 4400 value = 9.955 1&#45;&gt;2 5 Enclosure ≤ 4.5 mse = 0.37 samples = 12415 value = 10.484 1&#45;&gt;5 3 mse = 0.315 samples = 2002 value = 10.226 2&#45;&gt;3 4 mse = 0.232 samples = 2398 value = 9.728 2&#45;&gt;4 6 mse = 0.29 samples = 7193 value = 10.736 5&#45;&gt;6 7 mse = 0.272 samples = 5222 value = 10.137 5&#45;&gt;7 9 fiProductClassDesc ≤ 40.5 mse = 0.101 samples = 468 value = 8.988 8&#45;&gt;9 12 saleElapsed ≤ 1217462400.0 mse = 0.082 samples = 2717 value = 9.427 8&#45;&gt;12 10 mse = 0.069 samples = 293 value = 8.896 9&#45;&gt;10 11 mse = 0.118 samples = 175 value = 9.143 9&#45;&gt;11 13 mse = 0.062 samples = 1347 value = 9.529 12&#45;&gt;13 14 mse = 0.081 samples = 1370 value = 9.328 12&#45;&gt;14",
            "url": "https://sra00.github.io/notebookposts/2021/11/06/ML1.html",
            "relUrl": "/2021/11/06/ML1.html",
            "date": " • Nov 6, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://sra00.github.io/notebookposts/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://sra00.github.io/notebookposts/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://sra00.github.io/notebookposts/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://sra00.github.io/notebookposts/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}